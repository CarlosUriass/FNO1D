{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2 = pd.read_csv('input_2.csv')\n",
    "\n",
    "input_2 = input_2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 3, 6001)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_2_res = input_2.reshape(6000, 3, 6001)\n",
    "\n",
    "input_2_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = input_2_res.shape  # 6000, 3, 6001\n",
    "\n",
    "# Crear array vacío para los datos normalizados con misma forma\n",
    "datos_normalizados = np.zeros_like(input_2_res)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for i in range(b): \n",
    "    # Tomamos todas las muestras para el canal i, forma (6000, 6001)\n",
    "    datos_canal = input_2_res[:, i, :]\n",
    "    datos_canal_norm = scaler.fit_transform(datos_canal)\n",
    "\n",
    "    # Guardamos la normalización en el resultado\n",
    "    datos_normalizados[:, i, :] = datos_canal_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00000000e+00, 4.67751556e-01, 5.73972182e-01, ...,\n",
       "         6.00396138e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 5.16507807e-01, 5.06759789e-01, ...,\n",
       "         5.58031939e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 5.61223056e-01, 4.86514237e-01, ...,\n",
       "         4.54977361e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[1.66694449e-04, 4.67747122e-01, 5.74102094e-01, ...,\n",
       "         6.00398208e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.66694449e-04, 5.16502970e-01, 5.06907610e-01, ...,\n",
       "         5.58038347e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.66694449e-04, 5.61216665e-01, 4.86725553e-01, ...,\n",
       "         4.54984023e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[3.33388898e-04, 4.67741950e-01, 5.74298383e-01, ...,\n",
       "         6.00403788e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [3.33388898e-04, 5.16495506e-01, 5.07112949e-01, ...,\n",
       "         5.58045207e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [3.33388898e-04, 5.61217354e-01, 4.86908947e-01, ...,\n",
       "         4.54989452e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[9.99666611e-01, 4.67756016e-01, 5.74040784e-01, ...,\n",
       "         6.00408824e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [9.99666611e-01, 5.16516550e-01, 5.06786575e-01, ...,\n",
       "         5.58028456e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [9.99666611e-01, 5.61230196e-01, 4.86493309e-01, ...,\n",
       "         4.54980058e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[9.99833306e-01, 4.67749858e-01, 5.73984020e-01, ...,\n",
       "         6.00402305e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [9.99833306e-01, 5.16507928e-01, 5.06742145e-01, ...,\n",
       "         5.58031621e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [9.99833306e-01, 5.61223756e-01, 4.86461983e-01, ...,\n",
       "         4.54974723e-01, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[1.00000000e+00, 4.67750905e-01, 5.73969075e-01, ...,\n",
       "         6.00396186e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.00000000e+00, 5.16508388e-01, 5.06741113e-01, ...,\n",
       "         5.58032358e-01, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.00000000e+00, 5.61225016e-01, 4.86465950e-01, ...,\n",
       "         4.54977665e-01, 0.00000000e+00, 0.00000000e+00]]],\n",
       "      shape=(6000, 3, 6001))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 3, 6001)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_normalizados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>p_arrival_sample</th>\n",
       "      <th>s_arrival_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>7.119410e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1.660000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1.204556e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1.286595e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1.307000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>5995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>5996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>5997</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1.109000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>5998</td>\n",
       "      <td>1243.8</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>5999</td>\n",
       "      <td>664.0</td>\n",
       "      <td>6.626438e-310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  p_arrival_sample  s_arrival_sample\n",
       "0              0             400.0      7.119410e+02\n",
       "1              1             601.0      1.660000e+03\n",
       "2              2             700.0      1.204556e+03\n",
       "3              3             400.0      1.286595e+03\n",
       "4              4             600.0      1.307000e+03\n",
       "...          ...               ...               ...\n",
       "5995        5995               0.0      0.000000e+00\n",
       "5996        5996               0.0      0.000000e+00\n",
       "5997        5997             900.0      1.109000e+03\n",
       "5998        5998            1243.8      0.000000e+00\n",
       "5999        5999             664.0     6.626438e-310\n",
       "\n",
       "[6000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.read_csv('output_2.csv')\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SismoDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # X: tensor (samples, channels, length)\n",
    "        # y: tensor (samples, 2)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Conversión a tensores torch\n",
    "X_tensor = torch.tensor(datos_normalizados, dtype=torch.float32)  # (6000, 3, 6001)\n",
    "y_tensor = torch.tensor(targets, dtype=torch.float32)             # (6000, 2)\n",
    "\n",
    "dataset = SismoDataset(X_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1\n",
    "\n",
    "        self.scale = (1 / (in_channels*out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n",
    "\n",
    "    def compl_mul1d(self, input, weights):\n",
    "        # Multiplicación compleja espectral\n",
    "        return torch.einsum(\"bix,iox->box\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-1)//2 + 1, device=x.device, dtype=torch.cfloat)\n",
    "        out_ft[:, :, :self.modes1] = self.compl_mul1d(x_ft[:, :, :self.modes1], self.weights1)\n",
    "        \n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x\n",
    "\n",
    "class FNO1dRegression(nn.Module):\n",
    "    def __init__(self, modes, width, output_dim=2):\n",
    "        super(FNO1dRegression, self).__init__()\n",
    "\n",
    "        self.modes1 = modes\n",
    "        self.width = width\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.fc0 = nn.Linear(3, self.width)  # 3 canales/features de entrada\n",
    "\n",
    "        self.convs = nn.ModuleList([SpectralConv1d(self.width, self.width, self.modes1) for _ in range(4)])\n",
    "        self.ws = nn.ModuleList([nn.Conv1d(self.width, self.width, 1) for _ in range(4)])\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, self.output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels=3, length=6001)\n",
    "        # Pero fc0 espera último dim features, lo permutamos:\n",
    "        x = x.permute(0, 2, 1)  # ahora (batch, length, channels=3)\n",
    "        x = self.fc0(x)         # (batch, length, width)\n",
    "\n",
    "        x = x.permute(0, 2, 1)  # (batch, width, length)\n",
    "\n",
    "        for conv, w in zip(self.convs, self.ws):\n",
    "            x1 = conv(x)\n",
    "            x2 = w(x)\n",
    "            x = x1 + x2\n",
    "            x = F.relu(x)\n",
    "\n",
    "        # Pooling global en dimensión length para obtener vector (batch, width)\n",
    "        x = x.mean(dim=2)  # promedio sobre length\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)  # (batch, output_dim=2)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = FNO1dRegression(modes=16, width=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "def test_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "    return total_loss / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 524651.4759, Test Loss = 330748.0446\n",
      "Epoch 2: Train Loss = 329026.0189, Test Loss = 335798.6400\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    test_loss = test_epoch(model, test_loader, device)\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
